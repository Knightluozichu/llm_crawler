import base64
from io import BytesIO
from pathlib import Path
from typing import Dict

import pandas as pd
import streamlit as st

from data_processor import DataProcessor
from visualizer import DataVisualizer
from llm_hr import LLMHR  # æ–°å¢

# ========== ä¸» UI ç±» ==========

class JobUI:
    """
    Streamlit UI ä¸»ç•Œé¢å°è£…ç±»ã€‚
    - è´Ÿè´£åŠ è½½æ•°æ®ï¼Œç®¡ç†ä¼šè¯çŠ¶æ€ï¼Œå¹¶ä¸ DataProcessorã€DataVisualizer é…åˆè¿›è¡Œå¯è§†åŒ–ä¸æ±‚èŒåŠŸèƒ½ã€‚
    """
    def __init__(self, data_root: Path):
        self.data_root = data_root
        self.data_dir = data_root / 'data'
        self._init_session_state()
        self.data_processor = None
        self.visualizer = None
        self.hr = LLMHR()  # æ–°å¢ï¼šä½¿ç”¨ LLMHR
        
    def _init_session_state(self):
        """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
        if 'resume_text' not in st.session_state:
            st.session_state['resume_text'] = ""
        if 'llm_mode' not in st.session_state:
            st.session_state['llm_mode'] = "æœ¬åœ° Ollama"
        if 'local_model' not in st.session_state:
            st.session_state['local_model'] = ""
        if 'openai_key' not in st.session_state:
            st.session_state['openai_key'] = ""
        if 'data_loaded' not in st.session_state:
            st.session_state['data_loaded'] = False
        # æ–°å¢ï¼šä¼˜åŒ–ç®€å†ç›¸å…³çš„çŠ¶æ€
        if 'optimized_resumes' not in st.session_state:
            st.session_state['optimized_resumes'] = {}
        if 'button_clicked' not in st.session_state:
            st.session_state['button_clicked'] = {}
        if 'job_matches' not in st.session_state:
            st.session_state['job_matches'] = None
        if 'matched_jobs_displayed' not in st.session_state:
            st.session_state['matched_jobs_displayed'] = False
        if 'current_job_index' not in st.session_state:
            st.session_state['current_job_index'] = None
        if 'resume_generation_requested' not in st.session_state:
            st.session_state['resume_generation_requested'] = {}
        if 'deepseek_key' not in st.session_state:
            st.session_state['deepseek_key'] = ""

    def _load_data(self):
        """
        ä¾§è¾¹æ æˆ–é¡µé¢é€‰æ‹© CSV æ–‡ä»¶å¹¶åŠ è½½ï¼Œ
        ç”¨ DataProcessor è¿›è¡Œé¢„å¤„ç†ï¼Œç„¶ååˆå§‹åŒ– DataVisualizerã€‚
        """
        csv_files = [f for f in self.data_dir.glob('*.csv')]
        if not csv_files:
            st.error("æ•°æ®ç›®å½•ä¸‹æœªæ‰¾åˆ°ä»»ä½• CSV æ–‡ä»¶ï¼Œè¯·å…ˆå‡†å¤‡å¥½æ•°æ®æ–‡ä»¶ã€‚")
            return None
        
        selected_file = st.selectbox("è¯·é€‰æ‹©æ•°æ®æ–‡ä»¶", [f.name for f in csv_files])
        
        if st.button("åŠ è½½å¹¶åˆ†ææ•°æ®") or st.session_state.get('data_loaded', False):
            data_file = self.data_dir / selected_file
            try:
                if not data_file.exists():
                    st.error(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
                    return None
                    
                # åªæœ‰åœ¨æœªåŠ è½½æˆ–æ–‡ä»¶å˜åŒ–æ—¶æ‰é‡æ–°åŠ è½½
                if (not self.data_processor or 
                    str(data_file) != getattr(self.data_processor, 'current_file', None)):
                    self.data_processor = DataProcessor(data_file)
                    self.visualizer = DataVisualizer(self.data_processor)
                    # ä¿å­˜å½“å‰æ–‡ä»¶è·¯å¾„ä»¥ä¾¿åç»­æ¯”è¾ƒ
                    self.data_processor.current_file = str(data_file)
                
                st.session_state['data_loaded'] = True
                st.success(f"æˆåŠŸåŠ è½½æ•°æ®æ–‡ä»¶: {selected_file}")
                
                return True
                
            except Exception as e:
                st.error(f"åŠ è½½æ•°æ®å¤±è´¥: {str(e)}")
                return None
        
    def _setup_llm_settings(self):
        """
        ä¾§è¾¹æ ï¼šè®¾ç½® LLM ç›¸å…³é…ç½®
        """
        st.sidebar.header("AI è®¾ç½®")
        mode_options = ["æœ¬åœ° Ollama", "OpenAI åœ¨çº¿æ¨¡å‹", "Deepseek åœ¨çº¿æ¨¡å‹"]
        llm_mode = st.sidebar.radio(
            "é€‰æ‹© LLM æ¨¡å¼",
            options=mode_options,
            key="llm_mode"  # ç›´æ¥ä½¿ç”¨ key ç®¡ç†é€‰ä¸­çš„å€¼
        )

        if llm_mode == "æœ¬åœ° Ollama":
            local_models = self.hr.get_local_models()  # æ–°å¼•ç”¨
            selected_model = st.sidebar.selectbox(
                "é€‰æ‹©æœ¬åœ°æ¨¡å‹",
                local_models,
                key="local_model_select"
            )
            st.session_state['local_model'] = selected_model
        elif llm_mode == "OpenAI åœ¨çº¿æ¨¡å‹":
            openai_key = st.sidebar.text_input(
                "è¾“å…¥ OpenAI API Key (å¿…å¡«)",
                value=st.session_state.get('openai_key', ""),
                type="password",
                key="openai_key_input"
            )
            st.session_state['openai_key'] = openai_key
        elif llm_mode == "Deepseek åœ¨çº¿æ¨¡å‹":  # ä¿æŒä¸ llm_hr.py ä¸­çš„åˆ¤æ–­ä¸€è‡´
            deepseek_key = st.sidebar.text_input(
                "è¾“å…¥ Deepseek API Key (å¿…å¡«)",
                value=st.session_state.get('deepseek_key', ""),
                type="password",
                key="deepseek_key_input"
            )
            st.session_state['deepseek_key'] = deepseek_key

    def setup_sidebar(self) -> Dict:
        """
        ä¾§è¾¹æ ï¼šè®¾ç½®å¤šé¡¹ç­›é€‰æ¡ä»¶å¹¶è¿”å›ç­›é€‰å™¨å­—å…¸ã€‚
        - è–ªèµ„èŒƒå›´ (min, max) (å•ä½ï¼šåƒå…ƒ)
        - work_exp (æœ€å¤§å¹´é™)
        - education (0~4)
        - company_type (å¤šé€‰)
        - welfare_tags (å¤šé€‰)
        
        :return: dict æ ¼å¼çš„å„é¡¹ç­›é€‰æ¡ä»¶
        """
        st.sidebar.header("ç­›é€‰æ¡ä»¶")
        
        if not (self.data_processor and self.visualizer):
            return {}
        
        df = self.visualizer.processed_data
        
        # è–ªèµ„èŒƒå›´
        min_val = int(df['avg_salary'].min()) if len(df) else 0
        max_val = int(df['avg_salary'].max()) if len(df) else 50
        salary_range = st.sidebar.slider(
            "è–ªèµ„èŒƒå›´ (åƒå…ƒ)",
            min_value=min_val,
            max_value=max_val,
            value=(min_val, max_val)
        )
        
        # å·¥ä½œç»éªŒ (work_exp)
        max_exp = int(df['work_exp'].max()) if len(df) else 10
        selected_exp = st.sidebar.slider(
            "æœ€å¤§å·¥ä½œç»éªŒ (å¹´)",
            min_value=0,
            max_value=max_exp,
            value=max_exp
        )
        
        # å­¦å†è¦æ±‚
        edu_options = ['ä¸é™', 'å¤§ä¸“', 'æœ¬ç§‘', 'ç¡•å£«', 'åšå£«']
        education = st.sidebar.select_slider(
            "æœ€ä½å­¦å†è¦æ±‚",
            options=edu_options,
            value='ä¸é™'
        )
        education_idx = edu_options.index(education)
        
        # å…¬å¸ç±»å‹
        company_types = df['company_type'].unique().tolist()
        selected_company_types = st.sidebar.multiselect(
            "å…¬å¸ç±»å‹",
            options=company_types,
            default=company_types
        )
        
        # ç¦åˆ©æ ‡ç­¾
        all_welfare_tags = []
        for tags in df['welfare_tags']:
            all_welfare_tags.extend(tags)
        welfare_options = list(set(all_welfare_tags))
        selected_welfare_tags = st.sidebar.multiselect(
            "ç¦åˆ©æ ‡ç­¾",
            options=welfare_options,
            default=[]
        )
        
        return {
            'salary_range': salary_range,
            'work_exp': selected_exp,
            'education': education_idx,
            'company_type': selected_company_types,
            'welfare_tags': selected_welfare_tags
        }

    def _handle_resume_upload(self):
        """
        é¡µé¢ä¸­ï¼šä¸Šä¼ å¹¶è§£æç®€å†æ–‡ä»¶ï¼ˆPDFã€Wordï¼‰ã€‚
        è§£æåå­˜å…¥ session_state['resume_text']ã€‚
        """
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ ç®€å†ï¼ˆPDFæˆ–Wordï¼‰",
            type=["pdf", "doc", "docx"],
            key="resume_uploader"
        )
        
        if uploaded_file is not None:
            file_type = uploaded_file.name.split('.')[-1].lower()
            file_bytes = uploaded_file.read()
            
            new_text = self.hr.parse_resume(file_bytes, file_type)  # æ–°å¼•ç”¨
            if new_text != st.session_state['resume_text']:
                st.session_state['resume_text'] = new_text
                st.success("ç®€å†ä¸Šä¼ å¹¶è§£ææˆåŠŸï¼")
                
                # è‡ªåŠ¨åŒ¹é…å¹¶æ‰“åˆ†
                if self.visualizer:
                    df = self.visualizer.processed_data
                    job_matches = self.hr.match_jobs_with_resume(  # æ–°å¼•ç”¨
                        resume_text=new_text,
                        job_df=df
                    )
                    st.session_state['auto_job_matches'] = job_matches
                    st.session_state['auto_resume_score'] = self.hr.score_resume(new_text)  # æ–°å¼•ç”¨

    def _show_basic_analysis_tab(self, tab):
        """
        é€‰é¡¹å¡ 1ï¼šæ˜¾ç¤ºåŸºç¡€å¯è§†åŒ–åˆ†æï¼ŒåŒ…æ‹¬è–ªèµ„ã€å­¦å†ã€ç»éªŒã€å…¬å¸ç±»å‹åˆ†å¸ƒç­‰ã€‚
        """
        with tab:
            st.subheader("åŸºç¡€åˆ†æ")
            if not self.visualizer:
                st.warning("è¯·å…ˆåŠ è½½æ•°æ®")
                return
            
            st.plotly_chart(self.visualizer.plot_salary_distribution(), use_container_width=True)
            
            col1, col2 = st.columns(2)
            with col1:
                st.plotly_chart(self.visualizer.plot_education_pie(), use_container_width=True)
            with col2:
                st.plotly_chart(self.visualizer.plot_experience_bar(), use_container_width=True)
                
            col3, col4 = st.columns(2)
            with col3:
                st.plotly_chart(self.visualizer.plot_company_type_pie(), use_container_width=True)
            with col4:
                st.info("æ›´å¤šå›¾è¡¨å¯åœ¨æ­¤æ‰©å±•ï¼Œå¦‚è¡Œä¸šåˆ†å¸ƒç­‰...")
            
            wordcloud_data = self.visualizer.generate_job_wordcloud()
            if wordcloud_data:
                st.image(
                    BytesIO(base64.b64decode(wordcloud_data)), 
                    caption='èŒä½æè¿°å…³é”®è¯äº‘å›¾'
                )
            else:
                st.warning("æ— æ³•ç”Ÿæˆè¯äº‘ï¼Œå¯èƒ½æ— æœ‰æ•ˆèŒä½æè¿°æ•°æ®")

    def _show_insights_tab(self, tab):
        """
        é€‰é¡¹å¡ 2ï¼šæ˜¾ç¤ºå²—ä½æ´å¯ŸæŠ¥è¡¨ï¼ŒåŒ…æ‹¬è–ªèµ„ã€å…³é”®è¯ç­‰å…³é”®æŒ‡æ ‡ã€‚
        """
        with tab:
            st.subheader("å²—ä½æ´å¯ŸæŠ¥è¡¨")
            if not self.visualizer:
                st.warning("è¯·å…ˆåŠ è½½æ•°æ®")
                return
            
            insights = self.visualizer.generate_job_insights()
            
            # å±•ç¤ºå…³é”®è–ªèµ„æŒ‡æ ‡
            col1, col2, col3 = st.columns(3)
            col1.metric("å¹³å‡è–ªèµ„", f"{insights['salary']['avg']} åƒå…ƒ")
            col2.metric("æœ€ä½è–ªèµ„", f"{insights['salary']['min']} åƒå…ƒ")
            col3.metric("æœ€é«˜è–ªèµ„", f"{insights['salary']['max']} åƒå…ƒ")
            
            # å±•ç¤ºé«˜é¢‘å…³é”®è¯
            st.write("èŒä½æè¿°é«˜é¢‘å…³é”®è¯ TOP 10ï¼š", ", ".join(insights['keywords']))
            
            # ç»˜åˆ¶æ´å¯Ÿå¯è§†åŒ–
            fig_salary, fig_keywords = self.visualizer.plot_insights_summary(insights)
            st.plotly_chart(fig_salary, use_container_width=True)
            st.plotly_chart(fig_keywords, use_container_width=True)
            
            # å¯¼å‡ºæ´å¯Ÿ
            if st.button("å¯¼å‡ºæ´å¯ŸæŠ¥è¡¨"):
                df_insights = pd.DataFrame.from_dict(insights, orient='index')
                csv_str = df_insights.to_csv()
                st.download_button(
                    label="ä¸‹è½½ CSV æŠ¥è¡¨",
                    data=csv_str,
                    file_name='job_insights.csv',
                    mime='text/csv'
                )

    def _show_job_search_tab(self, tab):
        """
        é€‰é¡¹å¡ 3ï¼šæ±‚èŒåŠŸèƒ½ï¼ŒåŒ…æ‹¬ç®€å†ä¸Šä¼ ã€åŒ¹é…ä¸ç®€å†å®šåˆ¶åŒ–ä¿®æ”¹ã€‚
        """
        with tab:
            st.subheader("æ±‚èŒä¸­å¿ƒï¼šç®€å†åŒ¹é…ä¸å®šåˆ¶åŒ–ä¿®æ”¹")
            
            # ä¸Šä¼ ç®€å†
            self._handle_resume_upload()
            
            # è‹¥å·²ä¸Šä¼ ç®€å†ï¼Œæ˜¾ç¤ºå½“å‰ç®€å†æ¦‚è§ˆ
            if st.session_state['resume_text']:
                st.write("---")
                st.subheader("å·²è§£æçš„ç®€å†å†…å®¹")
                # ç§»é™¤æˆªæ–­, ç›´æ¥è¾“å‡ºå…¨æ–‡
                st.write(st.session_state['resume_text'])
            
            st.warning("è¯·æ³¨æ„ä¿æŠ¤ä¸ªäººä¿¡æ¯éšç§ï¼Œå¦‚ä½¿ç”¨åœ¨çº¿æ¨¡å‹æ—¶éœ€ç¡®ä¿å·²äº†è§£ç›¸å…³é£é™©ã€‚")
            
            # ç¡®ä¿ session_state ä¸­å­˜åœ¨ä¼˜åŒ–åçš„ç®€å†
            if 'optimized_resumes' not in st.session_state:
                st.session_state['optimized_resumes'] = {}
            
            # å¼€å§‹åŒ¹é…
            if st.button("å¼€å§‹åŒ¹é…") or st.session_state['matched_jobs_displayed']:
                if not st.session_state['resume_text']:
                    st.error("è¯·å…ˆä¸Šä¼ å¹¶è§£æç®€å†æ–‡ä»¶ï¼")
                else:
                    if not st.session_state['matched_jobs_displayed']:
                        # åªåœ¨ç¬¬ä¸€æ¬¡ç‚¹å‡»æ—¶æ‰§è¡ŒåŒ¹é…
                        df = self.visualizer.processed_data
                        job_matches = self.hr.match_jobs_with_resume(  # æ–°å¼•ç”¨
                            resume_text=st.session_state['resume_text'],
                            job_df=df
                        )
                        st.session_state['job_matches'] = job_matches
                        st.session_state['matched_jobs_displayed'] = True
                    
                    if st.session_state['job_matches']:
                        st.success("å·²æ‰¾åˆ°å‰ 10 æ¡æœ€åŒ¹é…å²—ä½ï¼š")
                        for i, match in enumerate(st.session_state['job_matches']):
                            job_index = match['job_index']
                            
                            st.markdown(f"**{i+1}. å²—ä½åç§°:** {match['job_name']}")
                            st.markdown(f"**å…¬å¸åç§°:** {match['company_name']}")
                            st.markdown(f"**åŒ¹é…åº¦è¯„åˆ†:** {match['match_score']}")
                            st.markdown(f"**åŒ¹é…åŸå› :** {match['match_reason']}")
                            st.markdown(f"**è–ªèµ„èŒƒå›´:** {match['salary_range']}")
                            
                            # ç®€å†ä¿®æ”¹åŠŸèƒ½
                            with st.expander(f"ğŸ”§ ä¿®æ”¹ç®€å†ä»¥åŒ¹é…å²—ä½: {match['job_name']}"):
                                modify_button_key = f"modify_{job_index}"
                                
                                # æ£€æŸ¥æ˜¯å¦å·²ç»ç”Ÿæˆè¿‡ä¼˜åŒ–ç®€å†
                                already_optimized = job_index in st.session_state['optimized_resumes']
                                
                                if st.button(
                                    "æŸ¥çœ‹ä¼˜åŒ–åçš„ç®€å†" if already_optimized else f"ç”Ÿæˆé’ˆå¯¹ {match['job_name']} çš„ä¼˜åŒ–ç®€å†",
                                    key=modify_button_key
                                ):
                                    st.session_state['resume_generation_requested'][job_index] = True
                                
                                # å¤„ç†ç®€å†ç”Ÿæˆè¯·æ±‚
                                if st.session_state['resume_generation_requested'].get(job_index):
                                    if not already_optimized:
                                        with st.spinner("æ­£åœ¨ç”Ÿæˆä¼˜åŒ–åçš„ç®€å†..."):
                                            final_resume = self.hr.modify_resume_for_job(  # æ–°å¼•ç”¨
                                                original_resume=st.session_state['resume_text'],
                                                job_description=(
                                                    f"{match['job_name']} | {match['company_name']} | "
                                                    f"è–ªèµ„: {match['salary_range']}"
                                                ),
                                                llm_mode=(
                                                    "local" if st.session_state['llm_mode'] == "æœ¬åœ° Ollama"
                                                    else "openai" if st.session_state['llm_mode'] == "OpenAI åœ¨çº¿æ¨¡å‹"
                                                    else "Deepseek åœ¨çº¿æ¨¡å‹"  # ä¸ llm_hr.py ä¸­ä¿æŒä¸€è‡´
                                                ),
                                                openai_key=st.session_state.get('openai_key', ""),
                                                deepseek_key=st.session_state.get('deepseek_key', "")
                                            )
                                            st.session_state['optimized_resumes'][job_index] = {
                                                'resume': final_resume,
                                                'job_name': match['job_name']
                                            }
                                    
                                    # æ˜¾ç¤ºä¼˜åŒ–åçš„ç®€å†
                                    st.write("---")
                                    st.subheader("AIä¼˜åŒ–åçš„ç®€å†å†…å®¹:")
                                    st.write(st.session_state['optimized_resumes'][job_index]['resume'])
                                    
                                    # ä¸‹è½½æŒ‰é’®
                                    dl_data = st.session_state['optimized_resumes'][job_index]['resume'].encode("utf-8")
                                    st.download_button(
                                        label="ä¸‹è½½ä¿®æ”¹åç®€å† (txt)",
                                        data=dl_data,
                                        file_name=f"modified_resume_{match['job_name']}.txt",
                                        mime="text/plain"
                                    )

            # æ–°å¢ç®€å†æ‰“åˆ†åŠŸèƒ½
            if st.button("å¯¹ç®€å†è¿›è¡Œæ‰“åˆ†"):
                report = self.hr.score_resume(st.session_state['resume_text'])  # æ–°å¼•ç”¨
                st.subheader("ç®€å†è¯„åˆ†æŠ¥å‘Š")
                st.write(report)
                
            # æ˜¾ç¤ºä¼˜åŒ–åçš„ç®€å†
            if 'current_optimized_resume' in st.session_state:
                st.write("---")
                st.subheader(f"å·²ä¼˜åŒ–çš„ç®€å†å†…å®¹ (é’ˆå¯¹å²—ä½: {st.session_state['current_job_name']})")
                st.write(st.session_state['current_optimized_resume'])

    def run(self):
        """
        Streamlit åº”ç”¨çš„ä¸»å…¥å£å‡½æ•°
        """
        st.set_page_config(
            page_title="AIå²—ä½åˆ†æå¯è§†åŒ– & æ±‚èŒç³»ç»Ÿ",
            layout="wide",
            initial_sidebar_state="expanded"
        )

        # æ˜¾ç¤ºä¸»ç•Œé¢æ ‡é¢˜
        st.title("AI å²—ä½åˆ†æå¯è§†åŒ– & æ±‚èŒç³»ç»Ÿ")
        
        # ç¬¬ä¸€æ­¥ï¼šåŠ è½½æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
        load_result = self._load_data()
        
        # åªæœ‰æˆåŠŸåŠ è½½æ•°æ®åæ‰æ˜¾ç¤ºåç»­å†…å®¹
        if load_result or st.session_state.get('data_loaded', False):
            # ç¬¬äºŒæ­¥ï¼šè®¾ç½® LLM é…ç½®ï¼ˆä¾§è¾¹æ ï¼‰
            self._setup_llm_settings()
            
            # ç¬¬ä¸‰æ­¥ï¼šè®¾ç½®ç­›é€‰æ¡ä»¶ï¼ˆä¾§è¾¹æ ï¼‰
            filters = self.setup_sidebar()
            
            # åº”ç”¨ç­›é€‰æ¡ä»¶
            if self.data_processor and self.visualizer and filters:
                filtered_df = self.data_processor.filter_data(filters)
                self.visualizer.processed_data = filtered_df
            
            # ç¬¬å››æ­¥ï¼šåˆ›å»ºå¤šé€‰é¡¹å¡
            tab1, tab2, tab3 = st.tabs(["åŸºç¡€åˆ†æ", "å²—ä½æ´å¯ŸæŠ¥è¡¨", "æ±‚èŒ"])
            
            self._show_basic_analysis_tab(tab1)
            self._show_insights_tab(tab2)
            self._show_job_search_tab(tab3)
        else:
            st.info("è¯·å…ˆé€‰æ‹©å¹¶åŠ è½½æ•°æ®æ–‡ä»¶")
