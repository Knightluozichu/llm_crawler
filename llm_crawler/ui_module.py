import base64
from io import BytesIO
from pathlib import Path
from typing import Dict

import pandas as pd
import streamlit as st

from data_processor import DataProcessor
from data_save import JobDatabase
from visualizer import DataVisualizer
from llm_hr import LLMHR


class JobUI:
    """
    Streamlit UI ä¸»ç•Œé¢å°è£…ç±»ã€‚
    - è´Ÿè´£åŠ è½½æ•°æ®ï¼Œç®¡ç†ä¼šè¯çŠ¶æ€ï¼Œå¹¶ä¸ DataProcessorã€DataVisualizer é…åˆè¿›è¡Œå¯è§†åŒ–ä¸æ±‚èŒåŠŸèƒ½ã€‚
    """
    def __init__(self, data_root: Path):
        self.data_root = data_root
        self.data_dir = data_root / 'data'
        self._init_session_state()

        # ä»ä¼šè¯çŠ¶æ€è·å–æˆ–åˆå§‹åŒ–
        self.data_processor = st.session_state['data_processor']
        self.visualizer = st.session_state['visualizer']
        self.hr = LLMHR()

    def _init_session_state(self):
        """ç»Ÿä¸€åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ã€‚"""
        default_states = {
            'resume_text': "",
            'llm_mode': "æœ¬åœ° Ollama",
            'local_model': "",
            'openai_key': "",
            'data_loaded': False,
            'optimized_resumes': {},
            'button_clicked': {},
            'job_matches': None,
            'matched_jobs_displayed': False,
            'current_job_index': None,
            'resume_generation_requested': {},
            'deepseek_key': "",
            'data_processor': None,
            'visualizer': None,
            'global_storage_type': 'æ•°æ®åº“'
        }
        for k, v in default_states.items():
            if k not in st.session_state:
                st.session_state[k] = v

    def _load_data(self):
        """ç”¨æˆ·åœ¨ä¾§è¾¹æ æˆ–é¡µé¢ä¸Šé€‰æ‹© CSV æˆ–æ•°æ®åº“ï¼Œå¹¶åŠ è½½æ•°æ®ã€‚"""
        if st.session_state['data_loaded']:
            st.info("æ•°æ®å·²åŠ è½½ã€‚è‹¥éœ€é‡æ–°åŠ è½½ï¼Œè¯·é‡æ–°é€‰æ‹©å¹¶ç‚¹å‡»æŒ‰é’®ã€‚")

        source_type = st.selectbox("é€‰æ‹©æ•°æ®æº", ["CSVæ–‡ä»¶", "æ•°æ®åº“è¡¨"])
        if source_type == "CSVæ–‡ä»¶":
            csv_files = list(self.data_dir.glob('*.csv'))
            if not csv_files:
                st.error("æ•°æ®ç›®å½•ä¸‹æœªæ‰¾åˆ°ä»»ä½• CSV æ–‡ä»¶ï¼Œè¯·å…ˆå‡†å¤‡å¥½æ•°æ®æ–‡ä»¶ã€‚")
                return None

            selected_file = st.selectbox("è¯·é€‰æ‹©æ•°æ®æ–‡ä»¶", [f.name for f in csv_files])
            if st.button("åŠ è½½å¹¶åˆ†æCSVæ•°æ®"):
                data_file = self.data_dir / selected_file
                try:
                    if not data_file.exists():
                        st.error(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
                        return None

                    # åˆå§‹åŒ–æ•°æ®å¤„ç†ä¸å¯è§†åŒ–
                    self.data_processor = DataProcessor(data_file)
                    self.visualizer = DataVisualizer(self.data_processor)
                    st.session_state['data_processor'] = self.data_processor
                    st.session_state['visualizer'] = self.visualizer
                    st.session_state['data_loaded'] = True

                    st.success(f"æˆåŠŸåŠ è½½CSVæ–‡ä»¶: {selected_file}")
                    return True

                except Exception as e:
                    st.error(f"åŠ è½½æ•°æ®å¤±è´¥: {str(e)}")
                    return None
        else:
            # æ•°æ®åº“è¡¨åŠ è½½
            try:
                db = JobDatabase()
                table_names = db.get_table_names()
                if not table_names:
                    st.error("æ•°æ®åº“ä¸­æ²¡æœ‰æœ‰æ•ˆçš„è¡¨")
                    return None

                selected_table = st.selectbox("é€‰æ‹©æ•°æ®è¡¨", options=table_names)
                if st.button("åŠ è½½å¹¶åˆ†ææ•°æ®åº“æ•°æ®"):
                    table_data = db.get_table_data(selected_table)
                    if not table_data:
                        st.error(f"è¡¨ {selected_table} ä¸ºç©ºæˆ–è¯»å–å¤±è´¥")
                        return None

                    columns = [
                        'id', 'position_name', 'company_name', 'salary', 'work_city',
                        'work_exp', 'education', 'company_size', 'company_type',
                        'industry', 'position_url', 'job_summary', 'welfare', 'salary_count'
                    ]
                    df = pd.DataFrame(table_data, columns=columns)

                    temp_csv = self.data_dir / 'temp_db_data.csv'
                    df.to_csv(temp_csv, index=False)

                    self.data_processor = DataProcessor(temp_csv)
                    self.visualizer = DataVisualizer(self.data_processor)
                    st.session_state['data_processor'] = self.data_processor
                    st.session_state['visualizer'] = self.visualizer
                    st.session_state['data_loaded'] = True
                    st.session_state['selected_table'] = selected_table
                    st.session_state['table_data'] = table_data

                    st.success(f"æˆåŠŸåŠ è½½æ•°æ®è¡¨: {selected_table}")
                    return True

            except Exception as e:
                st.error(f"åŠ è½½æ•°æ®åº“å¤±è´¥: {str(e)}")
                return None

        return None

    def _setup_llm_settings(self):
        """è®¾ç½® LLM æ¨¡å¼ï¼ˆæœ¬åœ°/Ollamaã€OpenAIã€Deepseekï¼‰ã€‚"""
        st.sidebar.header("AI è®¾ç½®")
        mode_options = ["æœ¬åœ° Ollama", "OpenAI åœ¨çº¿æ¨¡å‹", "Deepseek åœ¨çº¿æ¨¡å‹"]
        llm_mode = st.sidebar.radio("é€‰æ‹© LLM æ¨¡å¼", options=mode_options, key="llm_mode")

        if llm_mode == "æœ¬åœ° Ollama":
            self.hr.change_llm_mode("local")
            local_models = self.hr.get_local_models()
            selected_model = st.sidebar.selectbox("é€‰æ‹©æœ¬åœ°æ¨¡å‹", local_models, key="local_model_select")
            st.session_state['local_model'] = selected_model
            self.hr.set_local_model(selected_model)
        elif llm_mode == "OpenAI åœ¨çº¿æ¨¡å‹":
            self.hr.change_llm_mode("openai")
            openai_key = st.sidebar.text_input(
                "è¾“å…¥ OpenAI API Key (å¿…å¡«)",
                value=st.session_state.get('openai_key', ""),
                type="password"
            )
            st.session_state['openai_key'] = openai_key
        else:
            self.hr.change_llm_mode("deepseek")
            deepseek_key = st.sidebar.text_input(
                "è¾“å…¥ Deepseek API Key (å¿…å¡«)",
                value=st.session_state.get('deepseek_key', ""),
                type="password"
            )
            st.session_state['deepseek_key'] = deepseek_key

    def setup_sidebar(self) -> Dict:
        """ä¾§è¾¹æ ç­›é€‰æ¡ä»¶ï¼šè–ªèµ„èŒƒå›´ã€å·¥ä½œç»éªŒã€å­¦å†ã€å…¬å¸ç±»å‹ã€ç¦åˆ©æ ‡ç­¾"""
        st.sidebar.header("ç­›é€‰æ¡ä»¶")

        if not (self.data_processor and self.visualizer):
            return {}

        df = self.visualizer.processed_data

        if len(df) > 0:
            min_val = max(0, int(df['avg_salary'].min()))
            max_val = max(50, int(df['avg_salary'].max()))
            if min_val == max_val:
                max_val = min_val + 10
        else:
            min_val, max_val = 0, 50

        salary_range = st.sidebar.slider(
            "è–ªèµ„èŒƒå›´ (åƒå…ƒ)",
            min_value=min_val,
            max_value=max_val,
            value=(min_val, max_val)
        )

        max_exp = int(df['work_exp'].max()) if len(df) else 10
        selected_exp = st.sidebar.slider("æœ€å¤§å·¥ä½œç»éªŒ (å¹´)", min_value=0, max_value=max_exp, value=max_exp)

        edu_options = ['ä¸é™', 'å¤§ä¸“', 'æœ¬ç§‘', 'ç¡•å£«', 'åšå£«']
        education = st.sidebar.select_slider("æœ€ä½å­¦å†è¦æ±‚", options=edu_options, value='ä¸é™')
        education_idx = edu_options.index(education)

        company_types = df['company_type'].unique().tolist()
        selected_company_types = st.sidebar.multiselect(
            "å…¬å¸ç±»å‹",
            options=company_types,
            default=company_types
        )

        # æ”¶é›† welfare_tags
        all_welfare_tags = []
        for tags in df.get('welfare_tags', []):
            if isinstance(tags, list):
                all_welfare_tags.extend(tags)
        welfare_options = list(set(all_welfare_tags))
        selected_welfare_tags = st.sidebar.multiselect(
            "ç¦åˆ©æ ‡ç­¾",
            options=welfare_options,
            default=[]
        )

        return {
            'salary_range': salary_range,
            'work_exp': selected_exp,
            'education': education_idx,
            'company_type': selected_company_types,
            'welfare_tags': selected_welfare_tags
        }

    def _handle_resume_upload(self):
        """ä¸Šä¼ å¹¶è§£æç®€å†æ–‡ä»¶ï¼ˆPDFã€Wordï¼‰ã€‚"""
        uploaded_file = st.file_uploader("ä¸Šä¼ ç®€å†ï¼ˆPDFæˆ–Wordï¼‰", type=["pdf", "doc", "docx"])
        if uploaded_file is not None:
            file_type = uploaded_file.name.split('.')[-1].lower()
            file_bytes = uploaded_file.read()
            new_text = self.hr.parse_resume(file_bytes, file_type)

            if new_text != st.session_state['resume_text']:
                st.session_state['resume_text'] = new_text
                st.success("ç®€å†ä¸Šä¼ å¹¶è§£ææˆåŠŸï¼")

    def _show_basic_analysis_tab(self, tab):
        """
        1. åŸºç¡€åˆ†æï¼š
           - è–ªèµ„åˆ†å¸ƒã€å­¦å†ã€ç»éªŒã€å…¬å¸ç±»å‹
           - è¯äº‘
           - å²—ä½åˆ†å¸ƒï¼ˆåŸå…ˆåœ¨ _show_job_distribution_tab çš„å†…å®¹ï¼‰
           - æŠ€èƒ½éœ€æ±‚ï¼ˆåŸå…ˆåœ¨ _show_skill_demand_tab çš„å†…å®¹ï¼‰
        """
        with tab:
            st.subheader("åŸºç¡€åˆ†æ")
            if not self.visualizer:
                st.warning("è¯·å…ˆåŠ è½½æ•°æ®")
                return

            # åŸå§‹åŸºç¡€åˆ†æ
            st.plotly_chart(self.visualizer.plot_salary_distribution(), use_container_width=True, 
                            key="basic_salary_dist")

            col1, col2 = st.columns(2)
            with col1:
                st.plotly_chart(self.visualizer.plot_education_pie(), use_container_width=True, 
                                key="basic_education_pie")
            with col2:
                st.plotly_chart(self.visualizer.plot_experience_bar(), use_container_width=True, 
                                key="basic_experience_bar")

            col3, col4 = st.columns(2)
            with col3:
                st.plotly_chart(self.visualizer.plot_company_type_pie(), use_container_width=True, 
                                key="basic_company_type_pie")
            with col4:
                st.plotly_chart(self.visualizer.plot_job_distribution_bar(), use_container_width=True, 
                            key="job_dist_bar")
                
            col5, col6 = st.columns(2)
            with col5:
                st.plotly_chart(self.visualizer.plot_job_distribution_pie(), use_container_width=True, 
                            key="job_dist_pie")
            with col6:
                st.plotly_chart(self.visualizer.plot_skill_bar(), use_container_width=True,
                            key="skill_bar_chart")
                
            wordcloud_data = self.visualizer.plot_wordcloud()
            if wordcloud_data:
                st.image(BytesIO(base64.b64decode(wordcloud_data)), caption='èŒä½æè¿°å…³é”®è¯äº‘å›¾')
            else:
                st.warning("æ— æ³•ç”Ÿæˆè¯äº‘ï¼Œå¯èƒ½æ— æœ‰æ•ˆèŒä½æè¿°æ•°æ®")


    def _show_insights_tab(self, tab):
        """2. å²—ä½æ´å¯ŸæŠ¥è¡¨"""
        with tab:
            st.subheader("å²—ä½æ´å¯ŸæŠ¥è¡¨")
            if not self.visualizer:
                st.warning("è¯·å…ˆåŠ è½½æ•°æ®")
                return

            insights = self.visualizer.generate_job_insights()
            col1, col2, col3 = st.columns(3)
            col1.metric("å¹³å‡è–ªèµ„", f"{insights['salary']['avg']} åƒå…ƒ")
            col2.metric("æœ€ä½è–ªèµ„", f"{insights['salary']['min']} åƒå…ƒ")
            col3.metric("æœ€é«˜è–ªèµ„", f"{insights['salary']['max']} åƒå…ƒ")

            st.write("èŒä½æè¿°é«˜é¢‘å…³é”®è¯ TOP 10ï¼š", ", ".join(insights['keywords']))

            fig_salary, fig_exp = self.visualizer.plot_insights_summary(insights)
            st.plotly_chart(fig_salary, use_container_width=True, key="insights_salary_dist")
            st.plotly_chart(fig_exp, use_container_width=True, key="insights_exp_bar")

            if st.button("å¯¼å‡ºæ´å¯ŸæŠ¥è¡¨"):
                df_insights = pd.DataFrame.from_dict(insights, orient='index')
                csv_str = df_insights.to_csv()
                st.download_button(
                    label="ä¸‹è½½ CSV æŠ¥è¡¨",
                    data=csv_str,
                    file_name='job_insights.csv',
                    mime='text/csv'
                )

    def _show_job_search_tab(self, tab):
        """3. æ±‚èŒä¸­å¿ƒï¼šç®€å†åŒ¹é…ã€å®šåˆ¶åŒ–ä¿®æ”¹ã€æ‰“åˆ†ã€‚"""
        with tab:
            st.subheader("æ±‚èŒä¸­å¿ƒï¼šç®€å†åŒ¹é…ä¸å®šåˆ¶åŒ–ä¿®æ”¹")
            self._handle_resume_upload()

            if st.session_state['resume_text']:
                st.write("---")
                st.subheader("å·²è§£æçš„ç®€å†å†…å®¹")
                st.write(st.session_state['resume_text'])

            st.warning("è¯·æ³¨æ„ä¿æŠ¤ä¸ªäººä¿¡æ¯éšç§ï¼Œå¦‚ä½¿ç”¨åœ¨çº¿æ¨¡å‹æ—¶éœ€ç¡®ä¿å·²äº†è§£ç›¸å…³é£é™©ã€‚")

            if st.button("å¼€å§‹åŒ¹é…") or st.session_state['matched_jobs_displayed']:
                if not st.session_state['resume_text']:
                    st.error("è¯·å…ˆä¸Šä¼ å¹¶è§£æç®€å†æ–‡ä»¶ï¼")
                else:
                    if not st.session_state['matched_jobs_displayed']:
                        df = self.visualizer.processed_data
                        # job_matches = self.hr.match_jobs_with_resume(
                        job_matches = self.hr.match_jobs_with_resume_llm(
                            resume_text=st.session_state['resume_text'],
                            job_df=df
                        )
                        st.session_state['job_matches'] = job_matches
                        st.session_state['matched_jobs_displayed'] = True

                    if st.session_state['job_matches']:
                        st.success("å·²æ‰¾åˆ°å‰ 10 æ¡æœ€åŒ¹é…å²—ä½ï¼š")
                        for i, match in enumerate(st.session_state['job_matches']):
                            job_index = match['job_index']
                            st.markdown(f"**{i+1}. å²—ä½åç§°:** {match['job_name']}")
                            st.markdown(f"**å…¬å¸åç§°:** {match['company_name']}")
                            st.markdown(f"**åŒ¹é…åº¦è¯„åˆ†:** {match['match_score']}")
                            st.markdown(f"**åŒ¹é…åŸå› :** {match['match_reason']}")
                            st.markdown(f"**è–ªèµ„èŒƒå›´:** {match['salary_range']}")

                            with st.expander(f"ğŸ”§ ä¿®æ”¹ç®€å†ä»¥åŒ¹é…å²—ä½: {match['job_name']}"):
                                modify_button_key = f"modify_{job_index}"
                                already_optimized = job_index in st.session_state['optimized_resumes']

                                if st.button(
                                    "æŸ¥çœ‹ä¼˜åŒ–åçš„ç®€å†" if already_optimized else f"ç”Ÿæˆé’ˆå¯¹ {match['job_name']} çš„ä¼˜åŒ–ç®€å†",
                                    key=modify_button_key
                                ):
                                    st.session_state['resume_generation_requested'][job_index] = True

                                if st.session_state['resume_generation_requested'].get(job_index):
                                    if not already_optimized:
                                        with st.spinner("æ­£åœ¨ç”Ÿæˆä¼˜åŒ–åçš„ç®€å†..."):
                                            final_resume = self.hr.modify_resume_for_job(
                                                original_resume=st.session_state['resume_text'],
                                                job_description=(
                                                    f"{match['job_name']} | {match['company_name']} | "
                                                    f"è–ªèµ„: {match['salary_range']}"
                                                ),
                                                # llm_mode=(
                                                #     "local" if st.session_state['llm_mode'] == "æœ¬åœ° Ollama"
                                                #     else "openai" if st.session_state['llm_mode'] == "OpenAI åœ¨çº¿æ¨¡å‹"
                                                #     else "Deepseek åœ¨çº¿æ¨¡å‹"
                                                # ),
                                                # openai_key=st.session_state.get('openai_key', ""),
                                                # deepseek_key=st.session_state.get('deepseek_key', "")
                                            )
                                            st.session_state['optimized_resumes'][job_index] = {
                                                'resume': final_resume,
                                                'job_name': match['job_name']
                                            }

                                    st.write("---")
                                    st.subheader("AIä¼˜åŒ–åçš„ç®€å†å†…å®¹:")
                                    st.write(st.session_state['optimized_resumes'][job_index]['resume'])

                                    dl_data = st.session_state['optimized_resumes'][job_index]['resume'].encode("utf-8")
                                    st.download_button(
                                        label="ä¸‹è½½ä¿®æ”¹åç®€å† (txt)",
                                        data=dl_data,
                                        file_name=f"modified_resume_{match['job_name']}.txt",
                                        mime="text/plain"
                                    )

            if st.button("å¯¹ç®€å†è¿›è¡Œæ‰“åˆ†"):
                # report = self.hr.score_resume(st.session_state['resume_text'])
                report = self.hr.score_resume_llm(st.session_state['resume_text'])
                st.subheader("ç®€å†è¯„åˆ†æŠ¥å‘Š")
                st.write(report)

    def run(self):
        """Streamlit åº”ç”¨ä¸»å…¥å£ã€‚"""
        # Removed set_page_config as it's now in visual_data.py
        
        load_result = self._load_data()
        if load_result or st.session_state.get('data_loaded', False):
            self.data_processor = st.session_state['data_processor']
            self.visualizer = st.session_state['visualizer']

            self._setup_llm_settings()
            filters = self.setup_sidebar()
            if self.data_processor and self.visualizer and filters:
                filtered_df = self.data_processor.filter_data(filters)
                self.visualizer.processed_data = filtered_df

            # åªä¿ç•™ä¸‰ä¸ªä¸»è¦é€‰é¡¹å¡
            tab_basic, tab_insights, tab_jobsearch = st.tabs([
                "åŸºç¡€åˆ†æ",      # tab_basic
                "å²—ä½æ´å¯ŸæŠ¥è¡¨",  # tab_insights
                "æ±‚èŒä¸­å¿ƒ"       # tab_jobsearch
            ])

            # è°ƒç”¨å„è‡ªçš„æ˜¾ç¤ºæ–¹æ³•
            self._show_basic_analysis_tab(tab_basic)
            self._show_insights_tab(tab_insights)
            self._show_job_search_tab(tab_jobsearch)

        else:
            st.info("è¯·å…ˆé€‰æ‹©å¹¶åŠ è½½æ•°æ®æ–‡ä»¶")